{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Pytorch\n",
    "First, import the Pytorch dependencies.\n",
    "\n",
    "Then we define a set of workers, who will host the remote data while a local worker (or client) will manage the learning task. Note that we use virtual workers: these workers act just like normal remote workers except that they exist within the same Python program. Thus, we still serialize the commands to be exchanged between the workers but we donâ€™t actually send them over the network. This approach allows us to avoid network-related issues and focus on evaluation of the approach on a local setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import syft\n",
    "import wandb\n",
    "from typing import Dict\n",
    "import dotenv\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "USE_WANDB = False\n",
    "if USE_WANDB:\n",
    "    WANDB_KEY = os.getenv(\"WANDB_KEY\")\n",
    "ENTITY = os.getenv(\"ENTITY\")\n",
    "WORKER_IDS = [\"bob\", \"alice\", \"joe\", \"anna\", \"peter\"]\n",
    "\n",
    "class TrainingArgs():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 100\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = syft.TorchHook(torch)  # Add extra functionalities to PyTorch for Federated Learning\n",
    "\n",
    "workers = []\n",
    "for worker_id in WORKER_IDS:\n",
    "    workers.append(syft.VirtualWorker(hook, id=worker_id)) # Create a Virtual Workers\n",
    "\n",
    "# Define Learning Task Settings\n",
    "args = TrainingArgs()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()  # Use GPU if available unless CPU is specified\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "data_loader_kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Send to Workers\n",
    "In this scenario, the data is loaded and transformed from a local training dataset into a federated dataset using the `.federate` method: the dataset is split into two parts and sent to the workers Alice and Bob. This federated dataset is then given to a federated DataLoader which will iterate over remote batches. The test dataset remains unchanged as the local client will perform the test evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_loader(num_workers):\n",
    "    if num_workers > len(workers) or num_workers < 1:\n",
    "        raise ValueError(f\"Number of workers must be between 1 and {len(workers)}\")\n",
    "    \n",
    "    train_loader = syft.FederatedDataLoader(\n",
    "    train_dataset.federate(tuple(workers[:num_workers])),  # Distribute the dataset across all workers\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        **data_loader_kwargs\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True,\n",
    "    **data_loader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Definition\n",
    "- Two Convolutional Layers: 20 kernels of size 5x5 and 50 kernels of size 5x5\n",
    "- Two Fully Connected Layers with 500 and 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_workers):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(50 * 5 * 5, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        now = datetime.now()\n",
    "        timestamp_str = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        run_name = f\"workers_{self.num_workers}_{timestamp_str}\"\n",
    "        if USE_WANDB:\n",
    "            self.logger = WandBLogger(model=self, run_name=run_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = functional.relu(self.conv1(x))\n",
    "        x = functional.max_pool2d(x, 2, 2)\n",
    "        x = functional.relu(self.conv2(x))\n",
    "        x = functional.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 50*5*5)\n",
    "        x = functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Testing Functions\n",
    "For training, since the data batches are distributed across Alice and Bob, the model must be sent to the correct location for each batch. Then, we perform all operations remotely with the same syntax as if we were working in a local PyTorch environment. Once finished, we retrieve the model updates and the loss to monitor improvements using the `.get()` method.\n",
    "\n",
    "For centralized training mode the `NUM_WORKERS = 1`. If greater than 1 creates federated dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(args, model, device, optimizer, epoch, num_workers):\n",
    "    assert isinstance(num_workers, int), \"num_workers should be of type int\"\n",
    "    train_loader = create_train_loader(num_workers)\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # Now it is a distributed dataset\n",
    "        model.send(data.location)  # Send the model to the correct location\n",
    "        # data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get()  # Retrieve the model back\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get()  # Retrieve the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLocation: {}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(train_loader), loss.item(), data.location))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    print(f\"Average train loss: {loss_avg}. Epoch: {epoch}\")\n",
    "    return loss_avg\n",
    "\n",
    "def test_model(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += functional.nll_loss(output, target, reduction='sum').item()  # Sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True)  # Get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {} ({:.0f}%)\\n'.format(\n",
    "        test_loss, accuracy,\n",
    "        100. * accuracy))\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of Weights and Biases for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.login(key=WANDB_KEY)\n",
    "class WandBLogger:\n",
    "\n",
    "    def __init__(self, enabled=True, \n",
    "                 model: torch.nn.modules=None, \n",
    "                 run_name: str=None) -> None:\n",
    "        \n",
    "        self.enabled = enabled\n",
    "\n",
    "        if self.enabled:\n",
    "            wandb.init(entity=ENTITY,\n",
    "                        project=\"federated_learning\",\n",
    "                        group=\"group_1\")\n",
    "            if run_name is None:\n",
    "                wandb.run.name = wandb.run.id    \n",
    "            else:\n",
    "                wandb.run.name = run_name  \n",
    "\n",
    "            if model is not None:\n",
    "                self.watch(model)         \n",
    "            \n",
    "    def watch(self, model, log_freq: int=1):\n",
    "        wandb.watch(model, log=\"all\", log_freq=log_freq)  \n",
    "\n",
    "    def log(self, log_dict: dict, commit=True, step=None):\n",
    "        if self.enabled:\n",
    "            if step:\n",
    "                wandb.log(log_dict, commit=commit, step=step)\n",
    "            else:\n",
    "                wandb.log(log_dict, commit=commit)\n",
    "\n",
    "    def finish(self):\n",
    "        if self.enabled:\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training(num_workers):\n",
    "    model = SimpleCNN(num_workers).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_loss = train_model(args, model, device, optimizer, epoch, num_workers)\n",
    "        test_accuracy, test_loss = test_model(args, model, device, test_loader)\n",
    "        if USE_WANDB:\n",
    "            model.logger.log(log_dict={\n",
    "                f\"train_loss\": train_loss,\n",
    "                f\"test_loss\": test_loss,\n",
    "                f\"test_accuracy\": test_accuracy\n",
    "            }, step = epoch)\n",
    "    if USE_WANDB:\n",
    "        model.logger.finish()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), f\"cifar10_cnn_{num_workers}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301908\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 1 [3000/50000 (6%)]\tLoss: 2.272936\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 1 [6000/50000 (12%)]\tLoss: 2.246877\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 1 [9000/50000 (18%)]\tLoss: 2.187723\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 2.165530\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 1 [15000/50000 (30%)]\tLoss: 2.082531\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 1.955761\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 1 [21000/50000 (42%)]\tLoss: 1.858393\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 1.887579\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 1 [27000/50000 (54%)]\tLoss: 1.828828\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1.972731\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 1 [33000/50000 (66%)]\tLoss: 1.909122\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 1.848814\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 1 [39000/50000 (78%)]\tLoss: 1.828916\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 1.765289\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 1 [45000/50000 (90%)]\tLoss: 1.554933\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.773678\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.9671498887679155. Epoch: 1\n",
      "\n",
      "Test set: Average loss: 1.7055, Accuracy: 0.3917 (39%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.710783\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 2 [3000/50000 (6%)]\tLoss: 1.620492\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 2 [6000/50000 (12%)]\tLoss: 1.659074\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 2 [9000/50000 (18%)]\tLoss: 1.554188\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 1.710538\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 2 [15000/50000 (30%)]\tLoss: 1.629656\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 1.564276\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 2 [21000/50000 (42%)]\tLoss: 1.477018\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 1.643122\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 2 [27000/50000 (54%)]\tLoss: 1.521469\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 1.495666\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 2 [33000/50000 (66%)]\tLoss: 1.718923\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 1.602493\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 2 [39000/50000 (78%)]\tLoss: 1.596800\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 1.438747\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 2 [45000/50000 (90%)]\tLoss: 1.446418\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.460839\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.5794413510490866. Epoch: 2\n",
      "\n",
      "Test set: Average loss: 1.4848, Accuracy: 0.465 (46%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.480303\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 3 [3000/50000 (6%)]\tLoss: 1.323108\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 3 [6000/50000 (12%)]\tLoss: 1.365359\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 3 [9000/50000 (18%)]\tLoss: 1.457163\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 1.403146\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 3 [15000/50000 (30%)]\tLoss: 1.516780\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 1.470790\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 3 [21000/50000 (42%)]\tLoss: 1.291802\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 1.303343\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 3 [27000/50000 (54%)]\tLoss: 1.426693\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 1.415609\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 3 [33000/50000 (66%)]\tLoss: 1.354709\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 1.305461\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 3 [39000/50000 (78%)]\tLoss: 1.488849\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 1.424793\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 3 [45000/50000 (90%)]\tLoss: 1.320182\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.318375\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.3921449745402616. Epoch: 3\n",
      "\n",
      "Test set: Average loss: 1.3924, Accuracy: 0.4995 (50%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.319470\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 4 [3000/50000 (6%)]\tLoss: 1.359511\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 4 [6000/50000 (12%)]\tLoss: 1.527590\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 4 [9000/50000 (18%)]\tLoss: 1.210849\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 1.438174\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 4 [15000/50000 (30%)]\tLoss: 1.485572\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 1.487550\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 4 [21000/50000 (42%)]\tLoss: 1.323097\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 1.446890\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 4 [27000/50000 (54%)]\tLoss: 1.396537\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1.276831\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 4 [33000/50000 (66%)]\tLoss: 1.499074\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 1.247878\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 4 [39000/50000 (78%)]\tLoss: 1.331954\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 1.287013\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 4 [45000/50000 (90%)]\tLoss: 1.312846\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 1.304924\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.3679859287598555. Epoch: 4\n",
      "\n",
      "Test set: Average loss: 1.3092, Accuracy: 0.5336 (53%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.246401\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 5 [3000/50000 (6%)]\tLoss: 1.196318\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 5 [6000/50000 (12%)]\tLoss: 1.183430\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 5 [9000/50000 (18%)]\tLoss: 1.142136\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 1.210974\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 5 [15000/50000 (30%)]\tLoss: 1.472071\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 1.355299\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 5 [21000/50000 (42%)]\tLoss: 1.233267\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 1.108618\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 5 [27000/50000 (54%)]\tLoss: 1.172255\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1.306998\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 5 [33000/50000 (66%)]\tLoss: 1.347404\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 1.272721\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 5 [39000/50000 (78%)]\tLoss: 1.465625\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 1.140942\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 5 [45000/50000 (90%)]\tLoss: 1.290095\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.287839\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.2607289763057934. Epoch: 5\n",
      "\n",
      "Test set: Average loss: 1.2759, Accuracy: 0.5511 (55%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.224733\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 6 [3000/50000 (6%)]\tLoss: 1.396299\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 6 [6000/50000 (12%)]\tLoss: 1.304585\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 6 [9000/50000 (18%)]\tLoss: 1.168243\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 1.230158\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 6 [15000/50000 (30%)]\tLoss: 1.226068\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 1.154154\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 6 [21000/50000 (42%)]\tLoss: 1.111462\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 1.227648\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 6 [27000/50000 (54%)]\tLoss: 1.138960\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 1.156769\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 6 [33000/50000 (66%)]\tLoss: 1.128880\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 1.209368\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 6 [39000/50000 (78%)]\tLoss: 1.209852\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 1.220151\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 6 [45000/50000 (90%)]\tLoss: 1.340664\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.145115\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.2113593606387867. Epoch: 6\n",
      "\n",
      "Test set: Average loss: 1.1909, Accuracy: 0.5788 (58%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.271254\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 7 [3000/50000 (6%)]\tLoss: 1.079413\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 7 [6000/50000 (12%)]\tLoss: 1.286449\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 7 [9000/50000 (18%)]\tLoss: 1.085115\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 1.220352\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 7 [15000/50000 (30%)]\tLoss: 1.196640\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 1.157516\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 7 [21000/50000 (42%)]\tLoss: 1.110208\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 1.138116\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 7 [27000/50000 (54%)]\tLoss: 1.100601\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 1.313591\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 7 [33000/50000 (66%)]\tLoss: 1.258515\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 0.982585\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 7 [39000/50000 (78%)]\tLoss: 0.935948\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 1.299809\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 7 [45000/50000 (90%)]\tLoss: 1.114263\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 1.362070\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.1713203717680538. Epoch: 7\n",
      "\n",
      "Test set: Average loss: 1.1724, Accuracy: 0.5876 (59%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.333043\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 8 [3000/50000 (6%)]\tLoss: 1.089427\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 8 [6000/50000 (12%)]\tLoss: 1.200822\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 8 [9000/50000 (18%)]\tLoss: 1.182932\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 1.184466\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 8 [15000/50000 (30%)]\tLoss: 0.989076\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 1.111788\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 8 [21000/50000 (42%)]\tLoss: 1.221572\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 0.947657\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 8 [27000/50000 (54%)]\tLoss: 1.275838\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 1.034012\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 8 [33000/50000 (66%)]\tLoss: 1.040960\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 1.064953\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 8 [39000/50000 (78%)]\tLoss: 1.200697\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 1.062095\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 8 [45000/50000 (90%)]\tLoss: 1.115061\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 1.136141\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 1.1288551968686722. Epoch: 8\n",
      "\n",
      "Test set: Average loss: 1.0873, Accuracy: 0.617 (62%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.977698\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 9 [3000/50000 (6%)]\tLoss: 0.996099\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 9 [6000/50000 (12%)]\tLoss: 0.996164\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 9 [9000/50000 (18%)]\tLoss: 1.248479\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 0.930455\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 9 [15000/50000 (30%)]\tLoss: 0.935064\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 0.945910\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 9 [21000/50000 (42%)]\tLoss: 1.018215\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.945592\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 9 [27000/50000 (54%)]\tLoss: 0.949168\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.958800\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 9 [33000/50000 (66%)]\tLoss: 0.974502\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 1.021352\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 9 [39000/50000 (78%)]\tLoss: 1.055627\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 0.990643\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 9 [45000/50000 (90%)]\tLoss: 0.969347\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.757584\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.9806294020484475. Epoch: 9\n",
      "\n",
      "Test set: Average loss: 1.0654, Accuracy: 0.6259 (63%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.936036\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 10 [3000/50000 (6%)]\tLoss: 1.095089\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 10 [6000/50000 (12%)]\tLoss: 0.822783\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 10 [9000/50000 (18%)]\tLoss: 0.887135\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 1.001683\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 10 [15000/50000 (30%)]\tLoss: 1.129760\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 10 [18000/50000 (36%)]\tLoss: 0.896353\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 10 [21000/50000 (42%)]\tLoss: 1.122824\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 0.811107\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 10 [27000/50000 (54%)]\tLoss: 0.951689\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 1.046710\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 10 [33000/50000 (66%)]\tLoss: 0.848206\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 0.850868\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 10 [39000/50000 (78%)]\tLoss: 1.100934\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 10 [42000/50000 (84%)]\tLoss: 1.199848\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 10 [45000/50000 (90%)]\tLoss: 0.861006\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.984826\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.9733445188578438. Epoch: 10\n",
      "\n",
      "Test set: Average loss: 1.0186, Accuracy: 0.6441 (64%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.907086\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 11 [3000/50000 (6%)]\tLoss: 0.997648\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 11 [6000/50000 (12%)]\tLoss: 0.861871\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 11 [9000/50000 (18%)]\tLoss: 0.931462\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 11 [12000/50000 (24%)]\tLoss: 0.877774\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 11 [15000/50000 (30%)]\tLoss: 1.024944\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 11 [18000/50000 (36%)]\tLoss: 0.857658\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 11 [21000/50000 (42%)]\tLoss: 0.805757\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 11 [24000/50000 (48%)]\tLoss: 0.834215\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 11 [27000/50000 (54%)]\tLoss: 1.054327\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 0.864418\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 11 [33000/50000 (66%)]\tLoss: 0.824122\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 11 [36000/50000 (72%)]\tLoss: 0.929792\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 11 [39000/50000 (78%)]\tLoss: 0.852775\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 11 [42000/50000 (84%)]\tLoss: 1.025147\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 11 [45000/50000 (90%)]\tLoss: 0.978191\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 1.040912\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.9216529201058781. Epoch: 11\n",
      "\n",
      "Test set: Average loss: 0.9864, Accuracy: 0.6514 (65%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.854266\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 12 [3000/50000 (6%)]\tLoss: 0.892194\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 12 [6000/50000 (12%)]\tLoss: 0.906183\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 12 [9000/50000 (18%)]\tLoss: 0.990602\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 12 [12000/50000 (24%)]\tLoss: 0.895379\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 12 [15000/50000 (30%)]\tLoss: 0.767048\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 12 [18000/50000 (36%)]\tLoss: 0.864512\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 12 [21000/50000 (42%)]\tLoss: 1.017531\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 12 [24000/50000 (48%)]\tLoss: 1.124632\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 12 [27000/50000 (54%)]\tLoss: 1.072453\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 0.894507\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 12 [33000/50000 (66%)]\tLoss: 0.919705\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 12 [36000/50000 (72%)]\tLoss: 0.979226\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 12 [39000/50000 (78%)]\tLoss: 1.027840\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 12 [42000/50000 (84%)]\tLoss: 0.838318\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 12 [45000/50000 (90%)]\tLoss: 0.783891\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 0.808420\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.9198062384829802. Epoch: 12\n",
      "\n",
      "Test set: Average loss: 0.9714, Accuracy: 0.6622 (66%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.900009\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 13 [3000/50000 (6%)]\tLoss: 0.593303\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 13 [6000/50000 (12%)]\tLoss: 0.787031\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 13 [9000/50000 (18%)]\tLoss: 0.767913\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 13 [12000/50000 (24%)]\tLoss: 1.109153\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 13 [15000/50000 (30%)]\tLoss: 1.138631\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 13 [18000/50000 (36%)]\tLoss: 0.790755\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 13 [21000/50000 (42%)]\tLoss: 0.898071\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 13 [24000/50000 (48%)]\tLoss: 0.816402\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 13 [27000/50000 (54%)]\tLoss: 0.730143\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 0.991055\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 13 [33000/50000 (66%)]\tLoss: 0.822884\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 13 [36000/50000 (72%)]\tLoss: 0.825171\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 13 [39000/50000 (78%)]\tLoss: 0.838659\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 13 [42000/50000 (84%)]\tLoss: 0.873644\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 13 [45000/50000 (90%)]\tLoss: 0.840383\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 0.926846\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.8617679020937752. Epoch: 13\n",
      "\n",
      "Test set: Average loss: 0.9826, Accuracy: 0.6582 (66%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.938518\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 14 [3000/50000 (6%)]\tLoss: 0.907440\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 14 [6000/50000 (12%)]\tLoss: 0.789946\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 14 [9000/50000 (18%)]\tLoss: 0.842083\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 14 [12000/50000 (24%)]\tLoss: 0.824320\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 14 [15000/50000 (30%)]\tLoss: 1.167500\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 14 [18000/50000 (36%)]\tLoss: 0.867636\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 14 [21000/50000 (42%)]\tLoss: 0.739201\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 14 [24000/50000 (48%)]\tLoss: 0.824302\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 14 [27000/50000 (54%)]\tLoss: 0.820016\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 14 [30000/50000 (60%)]\tLoss: 0.698373\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 14 [33000/50000 (66%)]\tLoss: 0.844632\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 14 [36000/50000 (72%)]\tLoss: 0.856319\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 14 [39000/50000 (78%)]\tLoss: 0.905269\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 14 [42000/50000 (84%)]\tLoss: 0.855865\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 14 [45000/50000 (90%)]\tLoss: 0.903768\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 14 [48000/50000 (96%)]\tLoss: 0.798243\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.8578488966997933. Epoch: 14\n",
      "\n",
      "Test set: Average loss: 0.9444, Accuracy: 0.6728 (67%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.955736\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 15 [3000/50000 (6%)]\tLoss: 0.764124\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 15 [6000/50000 (12%)]\tLoss: 0.734016\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 15 [9000/50000 (18%)]\tLoss: 0.962935\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 15 [12000/50000 (24%)]\tLoss: 0.767633\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 15 [15000/50000 (30%)]\tLoss: 0.837403\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 15 [18000/50000 (36%)]\tLoss: 0.710687\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 15 [21000/50000 (42%)]\tLoss: 0.790248\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 15 [24000/50000 (48%)]\tLoss: 0.734661\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 15 [27000/50000 (54%)]\tLoss: 0.762442\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 15 [30000/50000 (60%)]\tLoss: 0.607979\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 15 [33000/50000 (66%)]\tLoss: 1.067284\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 15 [36000/50000 (72%)]\tLoss: 0.840434\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 15 [39000/50000 (78%)]\tLoss: 0.758909\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 15 [42000/50000 (84%)]\tLoss: 0.808196\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 15 [45000/50000 (90%)]\tLoss: 0.874983\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 15 [48000/50000 (96%)]\tLoss: 0.948549\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.8191893942215863. Epoch: 15\n",
      "\n",
      "Test set: Average loss: 0.9290, Accuracy: 0.677 (68%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.646054\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 16 [3000/50000 (6%)]\tLoss: 0.718410\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 16 [6000/50000 (12%)]\tLoss: 0.794111\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 16 [9000/50000 (18%)]\tLoss: 0.844423\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 16 [12000/50000 (24%)]\tLoss: 0.712749\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 16 [15000/50000 (30%)]\tLoss: 0.745324\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 16 [18000/50000 (36%)]\tLoss: 0.752885\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 16 [21000/50000 (42%)]\tLoss: 0.685534\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 16 [24000/50000 (48%)]\tLoss: 0.796076\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 16 [27000/50000 (54%)]\tLoss: 0.646235\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 16 [30000/50000 (60%)]\tLoss: 0.896922\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 16 [33000/50000 (66%)]\tLoss: 0.604447\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 16 [36000/50000 (72%)]\tLoss: 0.718708\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 16 [39000/50000 (78%)]\tLoss: 0.678360\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 16 [42000/50000 (84%)]\tLoss: 0.892321\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 16 [45000/50000 (90%)]\tLoss: 0.727229\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 16 [48000/50000 (96%)]\tLoss: 0.775155\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.7432320678935331. Epoch: 16\n",
      "\n",
      "Test set: Average loss: 0.9214, Accuracy: 0.6754 (68%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.472874\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 17 [3000/50000 (6%)]\tLoss: 0.731567\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 17 [6000/50000 (12%)]\tLoss: 0.839897\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 17 [9000/50000 (18%)]\tLoss: 0.946272\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 17 [12000/50000 (24%)]\tLoss: 0.889049\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 17 [15000/50000 (30%)]\tLoss: 0.670861\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 17 [18000/50000 (36%)]\tLoss: 0.608162\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 17 [21000/50000 (42%)]\tLoss: 0.679896\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 17 [24000/50000 (48%)]\tLoss: 0.818426\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 17 [27000/50000 (54%)]\tLoss: 0.618921\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 17 [30000/50000 (60%)]\tLoss: 0.715255\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 17 [33000/50000 (66%)]\tLoss: 0.767155\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 17 [36000/50000 (72%)]\tLoss: 0.709161\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 17 [39000/50000 (78%)]\tLoss: 0.576989\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 17 [42000/50000 (84%)]\tLoss: 0.836982\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 17 [45000/50000 (90%)]\tLoss: 0.731784\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 17 [48000/50000 (96%)]\tLoss: 0.751967\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.7273658110814936. Epoch: 17\n",
      "\n",
      "Test set: Average loss: 0.8895, Accuracy: 0.6935 (69%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.648054\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 18 [3000/50000 (6%)]\tLoss: 0.577516\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 18 [6000/50000 (12%)]\tLoss: 0.790939\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 18 [9000/50000 (18%)]\tLoss: 0.691504\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 18 [12000/50000 (24%)]\tLoss: 0.859009\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 18 [15000/50000 (30%)]\tLoss: 0.512213\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 18 [18000/50000 (36%)]\tLoss: 0.814919\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 18 [21000/50000 (42%)]\tLoss: 0.651210\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 18 [24000/50000 (48%)]\tLoss: 0.970894\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 18 [27000/50000 (54%)]\tLoss: 0.668281\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 18 [30000/50000 (60%)]\tLoss: 0.622743\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 18 [33000/50000 (66%)]\tLoss: 0.988983\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 18 [36000/50000 (72%)]\tLoss: 0.755478\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 18 [39000/50000 (78%)]\tLoss: 0.482210\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 18 [42000/50000 (84%)]\tLoss: 0.628113\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 18 [45000/50000 (90%)]\tLoss: 0.608564\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 18 [48000/50000 (96%)]\tLoss: 0.627824\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.699909096255022. Epoch: 18\n",
      "\n",
      "Test set: Average loss: 0.9232, Accuracy: 0.6797 (68%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.867645\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 19 [3000/50000 (6%)]\tLoss: 0.757229\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 19 [6000/50000 (12%)]\tLoss: 0.735755\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 19 [9000/50000 (18%)]\tLoss: 0.570354\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 19 [12000/50000 (24%)]\tLoss: 0.625110\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 19 [15000/50000 (30%)]\tLoss: 0.747826\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 19 [18000/50000 (36%)]\tLoss: 0.728511\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 19 [21000/50000 (42%)]\tLoss: 0.811374\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 19 [24000/50000 (48%)]\tLoss: 0.493576\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 19 [27000/50000 (54%)]\tLoss: 0.823877\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 19 [30000/50000 (60%)]\tLoss: 0.702732\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 19 [33000/50000 (66%)]\tLoss: 0.714177\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 19 [36000/50000 (72%)]\tLoss: 0.585684\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 19 [39000/50000 (78%)]\tLoss: 0.696262\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 19 [42000/50000 (84%)]\tLoss: 0.611396\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 19 [45000/50000 (90%)]\tLoss: 0.724126\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 19 [48000/50000 (96%)]\tLoss: 0.632658\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.6957819111206952. Epoch: 19\n",
      "\n",
      "Test set: Average loss: 0.9546, Accuracy: 0.6793 (68%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.867244\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 20 [3000/50000 (6%)]\tLoss: 0.602380\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 20 [6000/50000 (12%)]\tLoss: 0.664357\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 20 [9000/50000 (18%)]\tLoss: 0.546525\tLocation: <VirtualWorker id:bob #objects:5>\n",
      "Train Epoch: 20 [12000/50000 (24%)]\tLoss: 0.669327\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 20 [15000/50000 (30%)]\tLoss: 0.664110\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 20 [18000/50000 (36%)]\tLoss: 0.663606\tLocation: <VirtualWorker id:alice #objects:5>\n",
      "Train Epoch: 20 [21000/50000 (42%)]\tLoss: 0.605007\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 20 [24000/50000 (48%)]\tLoss: 0.578687\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 20 [27000/50000 (54%)]\tLoss: 0.616343\tLocation: <VirtualWorker id:joe #objects:5>\n",
      "Train Epoch: 20 [30000/50000 (60%)]\tLoss: 0.837037\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 20 [33000/50000 (66%)]\tLoss: 0.720659\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 20 [36000/50000 (72%)]\tLoss: 0.514386\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 20 [39000/50000 (78%)]\tLoss: 0.640197\tLocation: <VirtualWorker id:anna #objects:5>\n",
      "Train Epoch: 20 [42000/50000 (84%)]\tLoss: 0.641484\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 20 [45000/50000 (90%)]\tLoss: 0.757705\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Train Epoch: 20 [48000/50000 (96%)]\tLoss: 0.519213\tLocation: <VirtualWorker id:peter #objects:5>\n",
      "Average train loss: 0.6534275973544401. Epoch: 20\n",
      "\n",
      "Test set: Average loss: 0.9075, Accuracy: 0.6958 (70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_training(num_workers=len(WORKER_IDS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speml_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
