{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 11:42:08.849666: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 11:42:08.851754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 11:42:08.874474: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 11:42:08.874508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 11:42:08.874531: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 11:42:08.879170: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 11:42:08.879685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 11:42:09.846044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Wandb (Weights & Biases) is a machine learning platform that helps developers track experiments, visualize data, and share insights to improve models efficiently. (https://wandb.ai)\n",
    "\n",
    "**NUM_CLIENTS**: Number of federated Clients. The dataset is distributed equally among them\n",
    "\n",
    "**NUM_ROUNDS**: Number of federated rounds. One round represents a single round of Federated Averaging, which consists of pushing the server state (including the model parameters) to the clients, on-device training on their local data, collecting and averaging model updates, and producing a new updated model at the server.\n",
    "\n",
    "**BATCH_SIZE** = Number of samples distributed in one round to one client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WANDB = False\n",
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 10\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Model, Federated Training and Evaluation\n",
    "\n",
    "For federated learning we first must create a federated dataset from the regular dataset loaded with TF, by slicing it by the nr of federated clients and by the batch size. We can use https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices for that.\n",
    "\n",
    "Then the federated algorithm is built via:\n",
    "[build_weighted_fed_avg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg)\n",
    "or\n",
    "[build_unweighted_fed_avg](https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_unweighted_fed_avg)\n",
    "respectively where different optimizers and aggregators can be specified for our experiments\n",
    "\n",
    "To execute one round of federated learning we execute the [IterativeProcess.next-function](https://www.tensorflow.org/federated/api_docs/python/tff/templates/IterativeProcess)\n",
    "\n",
    "For good comparison to centralised learning we dont execute the evaluation in a federated way (this would also be possible with TFF), instead we copy the weights to a centralized clone of the model and evaluate the holdout testing set in each round.\n",
    "\n",
    "Metrics of the evaluation start with ``val_`` in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 11:57:03.498940: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.499074: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.515904: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.516062: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.783965: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.784063: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.880125: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.880240: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.884269: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.884323: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.889897: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.889965: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.896545: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.896609: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.907371: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.907447: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.914477: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.914559: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.922226: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.922310: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.930455: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.930558: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.937997: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.938070: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.939899: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.939949: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.943194: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.943267: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.947161: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.947233: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-31 11:57:03.966859: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-31 11:57:03.966955: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 2.0625 - categorical_accuracy: 0.3142 - 600ms/epoch - 2ms/step\n",
      "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.27886), ('loss', 1.9431365), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[2.062493324279785, 0.3142000138759613]\n",
      "313/313 - 1s - loss: 1.5602 - categorical_accuracy: 0.4363 - 675ms/epoch - 2ms/step\n",
      "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.37194), ('loss', 1.7072825), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.5601530075073242, 0.43630000948905945]\n",
      "313/313 - 1s - loss: 1.4250 - categorical_accuracy: 0.4899 - 562ms/epoch - 2ms/step\n",
      "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.4314), ('loss', 1.5560683), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.4249502420425415, 0.48989999294281006]\n",
      "313/313 - 1s - loss: 1.3335 - categorical_accuracy: 0.5247 - 561ms/epoch - 2ms/step\n",
      "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.47308), ('loss', 1.4565252), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.3334581851959229, 0.5246999859809875]\n",
      "313/313 - 1s - loss: 1.2600 - categorical_accuracy: 0.5582 - 573ms/epoch - 2ms/step\n",
      "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.50696), ('loss', 1.3734525), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.260005235671997, 0.5582000017166138]\n",
      "313/313 - 1s - loss: 1.2058 - categorical_accuracy: 0.5789 - 546ms/epoch - 2ms/step\n",
      "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.53438), ('loss', 1.3067292), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.205777883529663, 0.5788999795913696]\n",
      "313/313 - 1s - loss: 1.1560 - categorical_accuracy: 0.5971 - 592ms/epoch - 2ms/step\n",
      "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.55782), ('loss', 1.2477666), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.1559926271438599, 0.597100019454956]\n",
      "313/313 - 1s - loss: 1.1201 - categorical_accuracy: 0.6057 - 671ms/epoch - 2ms/step\n",
      "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.57896), ('loss', 1.193841), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.1200658082962036, 0.6057000160217285]\n",
      "313/313 - 1s - loss: 1.0887 - categorical_accuracy: 0.6173 - 592ms/epoch - 2ms/step\n",
      "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.59806), ('loss', 1.1458815), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.0886648893356323, 0.6172999739646912]\n",
      "313/313 - 1s - loss: 1.0583 - categorical_accuracy: 0.6294 - 534ms/epoch - 2ms/step\n",
      "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.61212), ('loss', 1.1063608), ('num_examples', 50000), ('num_batches', 2500)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.058306097984314, 0.6294000148773193]\n"
     ]
    }
   ],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.init(project=\"federated_learning\", group=\"group_1\", name=f\"tf_federated_differential_privacy_{NUM_CLIENTS}clients_{NUM_ROUNDS}rounds_{BATCH_SIZE}batchsize\")\n",
    "    \n",
    "# Create a function that returns a compiled Keras model\n",
    "def create_keras_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(20, (5, 5), activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(50, (5, 5), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model for use with TFF\n",
    "def model_fn():\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=(tf.TensorSpec(shape=[None, 32, 32, 3], dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=[None, 10], dtype=tf.float32)),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "#Convert the dataset to a federated dataset\n",
    "def preprocess(dataset):\n",
    "    def batch_format_fn(element):\n",
    "        return (tf.reshape(element['x'], [-1, 32, 32, 3]), tf.reshape(element['y'], [-1, 10]))\n",
    "    return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n",
    "\n",
    "client_data = np.array_split(x_train, NUM_CLIENTS)\n",
    "client_labels = np.array_split(y_train, NUM_CLIENTS)\n",
    "\n",
    "federated_train_data = [\n",
    "    preprocess(tf.data.Dataset.from_tensor_slices({'x': client_data[i], 'y': client_labels[i]}))\n",
    "    for i in range(NUM_CLIENTS)\n",
    "]\n",
    "\n",
    "# Create a federated averaging process\n",
    "# iterative_process = tff.learning.algorithms.build_unweighted_fed_avg( # EXPERIMENT: Unweighted training, also needed fro Differential Privacy\n",
    "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    # client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1), # EXPERIMENT: Different Client Optimizer\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    "    # server_optimizer_fn=lambda: keras.optimizers.Adam(), # EXPERIMENT: Different Server Optimizer\n",
    "    # model_aggregator=tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier=0.1, clients_per_round=NUM_CLIENTS), # EXPERIMENT: Differential Privacy\n",
    "    # model_aggregator=tff.learning.compression_aggregator() # EXPERIMENT: Compression\n",
    ")\n",
    "\n",
    "state = iterative_process.initialize()\n",
    "\n",
    "eval_model = create_keras_model()\n",
    "eval_model.compile(\n",
    "loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# Save the model for logging\n",
    "full_path = os.path.join(\"./\", \"model.keras\")\n",
    "eval_model.save(filepath=full_path)\n",
    "if USE_WANDB:\n",
    "    wandb.log_model(path=full_path, name=\"CIFAR10_CNN\")\n",
    "\n",
    "# Train the model for a few rounds\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    \n",
    "    model_weights = iterative_process.get_model_weights(state)\n",
    "    model_weights.assign_weights_to(eval_model)\n",
    "    eval_metrics = eval_model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    print(f'Round {round_num}, Metrics={metrics}, Val_Metrics={eval_metrics}')\n",
    "    \n",
    "    if USE_WANDB:\n",
    "        wandb.log({\n",
    "            'round': round_num,\n",
    "            'loss': metrics['client_work']['train']['loss'],\n",
    "            'categorical_accuracy': metrics['client_work']['train']['categorical_accuracy'],\n",
    "            'val_loss': eval_metrics[0],\n",
    "            'val_categorical_accuracy': eval_metrics[1]\n",
    "        })\n",
    "    \n",
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
