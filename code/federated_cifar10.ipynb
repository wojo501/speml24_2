{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 17:05:44.716025: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-28 17:05:44.717272: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-28 17:05:44.739263: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-28 17:05:44.739293: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-28 17:05:44.739315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-28 17:05:44.743886: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-28 17:05:44.744256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 17:05:45.429840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-07-28 17:05:50.313905: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:50.314002: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:50.327596: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:50.327664: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722179150.333113  261528 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1722179150.335108  261635 subchannel.cc:806] subchannel 0x7f05d0001610 {address=ipv6:%5B::1%5D:34541, args={grpc.client_channel_factory=0x7f079406d870, grpc.default_authority=localhost:34541, grpc.internal.channel_credentials=0x7f0794083000, grpc.internal.client_channel_call_destination=0x7f079a04b3d0, grpc.internal.event_engine=0x7f05d00139b0, grpc.internal.security_connector=0x7f05d0013a10, grpc.internal.subchannel_pool=0x7f079407c4d0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7f07942bc070, grpc.server_uri=dns:///localhost:34541}}: connect failed (UNKNOWN:Failed to connect to remote host: connect: Connection refused (111) {created_time:\"2024-07-28T17:05:50.334834239+02:00\"}), backing off for 999 ms\n",
      "I0000 00:00:1722179150.335257  261635 subchannel.cc:806] subchannel 0x7f05d0002220 {address=ipv4:127.0.0.1:34541, args={grpc.client_channel_factory=0x7f079406d870, grpc.default_authority=localhost:34541, grpc.internal.channel_credentials=0x7f0794083000, grpc.internal.client_channel_call_destination=0x7f079a04b3d0, grpc.internal.event_engine=0x7f05d0002150, grpc.internal.security_connector=0x7f05d0001d70, grpc.internal.subchannel_pool=0x7f079407c4d0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7f07942bc070, grpc.server_uri=dns:///localhost:34541}}: connect failed (UNKNOWN:Failed to connect to remote host: connect: Connection refused (111) {created_time:\"2024-07-28T17:05:50.335227154+02:00\"}), backing off for 1000 ms\n",
      "I0000 00:00:1722179151.336765  261651 subchannel.cc:761] subchannel 0x7f05d0001610 {address=ipv6:%5B::1%5D:34541, args={grpc.client_channel_factory=0x7f079406d870, grpc.default_authority=localhost:34541, grpc.internal.channel_credentials=0x7f0794083000, grpc.internal.client_channel_call_destination=0x7f079a04b3d0, grpc.internal.event_engine=0x7f05d00139b0, grpc.internal.security_connector=0x7f05d0013a10, grpc.internal.subchannel_pool=0x7f079407c4d0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7f07942bc070, grpc.server_uri=dns:///localhost:34541}}: backoff delay elapsed, reporting IDLE\n",
      "I0000 00:00:1722179151.336762  261650 subchannel.cc:761] subchannel 0x7f05d0002220 {address=ipv4:127.0.0.1:34541, args={grpc.client_channel_factory=0x7f079406d870, grpc.default_authority=localhost:34541, grpc.internal.channel_credentials=0x7f0794083000, grpc.internal.client_channel_call_destination=0x7f079a04b3d0, grpc.internal.event_engine=0x7f05d0002150, grpc.internal.security_connector=0x7f05d0001d70, grpc.internal.subchannel_pool=0x7f079407c4d0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7f07942bc070, grpc.server_uri=dns:///localhost:34541}}: backoff delay elapsed, reporting IDLE\n",
      "2024-07-28 17:05:52.596538: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.596650: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.697876: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.697944: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.701751: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.701803: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.707554: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.707633: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.714606: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.714681: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.726290: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.726356: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.732578: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.732637: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.739309: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.739372: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.747405: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.747466: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.754017: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.754082: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.755850: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.755906: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.758989: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.759056: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.763081: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.763150: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:05:52.775154: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:05:52.775228: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-07-28 17:06:05.962647: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2024-07-28 17:06:05.962792: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 2.0458 - categorical_accuracy: 0.2728 - 678ms/epoch - 2ms/step\n",
      "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.21112), ('loss', 2.1376772), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[2.045832633972168, 0.2727999985218048]\n",
      "313/313 - 1s - loss: 1.7829 - categorical_accuracy: 0.3768 - 593ms/epoch - 2ms/step\n",
      "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.29736), ('loss', 1.9451816), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.7828880548477173, 0.376800000667572]\n",
      "313/313 - 1s - loss: 1.8609 - categorical_accuracy: 0.3368 - 582ms/epoch - 2ms/step\n",
      "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.2987), ('loss', 2.0115178), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.8609166145324707, 0.3368000090122223]\n",
      "313/313 - 1s - loss: 1.6015 - categorical_accuracy: 0.4297 - 621ms/epoch - 2ms/step\n",
      "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.3638), ('loss', 1.775196), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.601514220237732, 0.42969998717308044]\n",
      "313/313 - 1s - loss: 1.5664 - categorical_accuracy: 0.4403 - 703ms/epoch - 2ms/step\n",
      "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.3813), ('loss', 1.7421196), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.5664093494415283, 0.44029998779296875]\n",
      "313/313 - 1s - loss: 1.4914 - categorical_accuracy: 0.4670 - 613ms/epoch - 2ms/step\n",
      "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.41014), ('loss', 1.6462336), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.4913886785507202, 0.46700000762939453]\n",
      "313/313 - 1s - loss: 1.4538 - categorical_accuracy: 0.4792 - 509ms/epoch - 2ms/step\n",
      "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.4261), ('loss', 1.6108022), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.453835129737854, 0.47920000553131104]\n",
      "313/313 - 0s - loss: 1.4193 - categorical_accuracy: 0.4918 - 498ms/epoch - 2ms/step\n",
      "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.44288), ('loss', 1.5666002), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.4192618131637573, 0.4918000102043152]\n",
      "313/313 - 0s - loss: 1.3856 - categorical_accuracy: 0.5028 - 453ms/epoch - 1ms/step\n",
      "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.45608), ('loss', 1.5214154), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.3855992555618286, 0.5027999877929688]\n",
      "313/313 - 0s - loss: 1.3510 - categorical_accuracy: 0.5165 - 470ms/epoch - 2ms/step\n",
      "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('categorical_accuracy', 0.472), ('loss', 1.4775299), ('num_examples', 50000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))]), Val_Metrics=[1.3510222434997559, 0.5164999961853027]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Create a function that returns a compiled Keras model\n",
    "def create_keras_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(20, (5, 5), activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(50, (5, 5), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model for use with TFF\n",
    "def model_fn():\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=(tf.TensorSpec(shape=[None, 32, 32, 3], dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=[None, 10], dtype=tf.float32)),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "### Step 3: Create Federated Data\n",
    "# Convert the dataset to a federated dataset\n",
    "def preprocess(dataset):\n",
    "    def batch_format_fn(element):\n",
    "        return (tf.reshape(element['x'], [-1, 32, 32, 3]), tf.reshape(element['y'], [-1, 10]))\n",
    "    \n",
    "    def augment_fn(element):\n",
    "        image, label = element['x'], element['y']\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "        return {'x': image, 'y': label}\n",
    "    \n",
    "    return dataset.map(augment_fn).batch(200).map(batch_format_fn)\n",
    "\n",
    "# Create a federated dataset\n",
    "NUM_CLIENTS = 10\n",
    "client_data = np.array_split(x_train, NUM_CLIENTS)\n",
    "client_labels = np.array_split(y_train, NUM_CLIENTS)\n",
    "\n",
    "federated_train_data = [\n",
    "    preprocess(tf.data.Dataset.from_tensor_slices({'x': client_data[i], 'y': client_labels[i]}))\n",
    "    for i in range(NUM_CLIENTS)\n",
    "]\n",
    "\n",
    "### Step 4: Define the Federated Learning Process\n",
    "# Create a federated averaging process\n",
    "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "# Initialize the process\n",
    "state = iterative_process.initialize()\n",
    "\n",
    "eval_model = create_keras_model()\n",
    "eval_model.compile(\n",
    "loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "# Train the model for a few rounds\n",
    "NUM_ROUNDS = 10\n",
    "for round_num in range(1, NUM_ROUNDS + 1):\n",
    "    state, metrics = iterative_process.next(state, federated_train_data)\n",
    "    \n",
    "    model_weights = iterative_process.get_model_weights(state)\n",
    "    model_weights.assign_weights_to(eval_model)\n",
    "    eval_metrics = eval_model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    print(f'Round {round_num}, Metrics={metrics}, Val_Metrics={eval_metrics}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
