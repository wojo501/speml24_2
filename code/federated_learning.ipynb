{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# Federated Learning for Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Before we start\n",
        "\n",
        "Before we start, please run the following to make sure that your environment is\n",
        "correctly setup. If you don't see a greeting, please refer to the\n",
        "[Installation](../install.md) guide for instructions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8BKyHkMxKHfV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-22 11:44:57.516753: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-22 11:44:57.518588: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-07-22 11:44:57.542174: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-22 11:44:57.542215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-22 11:44:57.542238: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-22 11:44:57.547404: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-07-22 11:44:57.547885: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-22 11:44:58.187501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1721648699.884573  801262 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
            "I0000 00:00:1721648699.886764  801264 subchannel.cc:806] subchannel 0x7ff51c0015d0 {address=ipv6:%5B::1%5D:44881, args={grpc.client_channel_factory=0x7ff5980141f0, grpc.default_authority=localhost:44881, grpc.internal.channel_credentials=0x7ff5980141d0, grpc.internal.client_channel_call_destination=0x7ff5a09e93d0, grpc.internal.event_engine=0x7ff51c013be0, grpc.internal.security_connector=0x7ff51c013980, grpc.internal.subchannel_pool=0x7ff598016db0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff5980165c0, grpc.server_uri=dns:///localhost:44881}}: connect failed (UNKNOWN:Failed to connect to remote host: connect: Connection refused (111) {created_time:\"2024-07-22T11:44:59.886669092+00:00\"}), backing off for 999 ms\n",
            "I0000 00:00:1721648699.886897  801264 subchannel.cc:806] subchannel 0x7ff51c002270 {address=ipv4:127.0.0.1:44881, args={grpc.client_channel_factory=0x7ff5980141f0, grpc.default_authority=localhost:44881, grpc.internal.channel_credentials=0x7ff5980141d0, grpc.internal.client_channel_call_destination=0x7ff5a09e93d0, grpc.internal.event_engine=0x7ff51c0021a0, grpc.internal.security_connector=0x7ff51c001da0, grpc.internal.subchannel_pool=0x7ff598016db0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff5980165c0, grpc.server_uri=dns:///localhost:44881}}: connect failed (UNKNOWN:Failed to connect to remote host: connect: Connection refused (111) {created_time:\"2024-07-22T11:44:59.886877051+00:00\"}), backing off for 1000 ms\n",
            "I0000 00:00:1721648700.887557  801278 subchannel.cc:761] subchannel 0x7ff51c002270 {address=ipv4:127.0.0.1:44881, args={grpc.client_channel_factory=0x7ff5980141f0, grpc.default_authority=localhost:44881, grpc.internal.channel_credentials=0x7ff5980141d0, grpc.internal.client_channel_call_destination=0x7ff5a09e93d0, grpc.internal.event_engine=0x7ff51c0021a0, grpc.internal.security_connector=0x7ff51c001da0, grpc.internal.subchannel_pool=0x7ff598016db0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff5980165c0, grpc.server_uri=dns:///localhost:44881}}: backoff delay elapsed, reporting IDLE\n",
            "I0000 00:00:1721648700.887557  801276 subchannel.cc:761] subchannel 0x7ff51c0015d0 {address=ipv6:%5B::1%5D:44881, args={grpc.client_channel_factory=0x7ff5980141f0, grpc.default_authority=localhost:44881, grpc.internal.channel_credentials=0x7ff5980141d0, grpc.internal.client_channel_call_destination=0x7ff5a09e93d0, grpc.internal.event_engine=0x7ff51c013be0, grpc.internal.security_connector=0x7ff51c013980, grpc.internal.subchannel_pool=0x7ff598016db0, grpc.max_message_length=2000000000, grpc.max_receive_message_length=2000000000, grpc.max_send_message_length=2000000000, grpc.primary_user_agent=grpc-python/1.65.1, grpc.resource_quota=0x7ff5980165c0, grpc.server_uri=dns:///localhost:44881}}: backoff delay elapsed, reporting IDLE\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Preparing the input data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NayDhCX6SjwE"
      },
      "outputs": [],
      "source": [
        "cifar100_train, cifar100_test = tff.simulation.datasets.cifar100.load_data()\n",
        "# display(cifar100_train.client_ids)\n",
        "# display(cifar100_test.element_type_structure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeX8BKgPfeFw"
      },
      "source": [
        "Inspect the dataset, of simulated client nr 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EsvSXGEMgd9G"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAunUlEQVR4nO3dfWyd9Xn/8c99nyfbiR9wHvxAEppAC6WQVMsgtWgZJRlJJjEo0QRtpYUOgWAOGmRd20wtFLbJjEotbZWGP8bIKjXQMjUg2AqD0Bh1S1iTEqX0ISX5ZU1o4gQCfrbPw31/f39kuDMk8L0SO1/bvF/oSMS+fPl7P53Lx+ecjyPnnBMAAGdYHHoBAID3JwYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACCIbOgFvF2apjp06JBqa2sVRVHo5QAAjJxz6uvrU2trq+L45I9zJtwAOnTokObOnRt6GQCA03Tw4EHNmTPnpJ8ftwG0fv16fe1rX1NXV5cWLVqkb3/727r00kvf8+tqa2slSdd/9hLl837Lm17wf6RUX1/jXStJifx7v9k/bOr9+pv93rVpans0WFPT4F07vabe1DsT1ZnqqwozvGtrptmOT2w4hV1aZeodKe+/DuMvszPZiqm+kG/wX4uqbYuJh7xLo8yAqXWknHetS/1rJSlN/FPEkrRs6u1cYqqvVPz7J0lq6m24C1Ic2+4nKhX/7bT8RqpYHNbX7vvqyP35yYzLAPr+97+vtWvX6sEHH9SSJUv0wAMPaPny5dqzZ49mz579rl/71kbm81nvAVQwDKBCwXaSWwZQvmy7U8nlM9611gHku+8kKW/cJ5nI/45ZkgqFgndtVZVtSIzvAPJf9/gPIP+hkolsQ9zyTHCUsd15jucASiwDKLHd1dkHkH//JLH1tg0g24lYqfifh6fylMh7fc24vAjh61//um6++WZ97nOf04UXXqgHH3xQNTU1+ud//ufx+HYAgElozAdQqVTSzp07tWzZst9/kzjWsmXLtG3btnfUF4tF9fb2jroBAKa+MR9Ar7/+upIkUVNT06iPNzU1qaur6x31HR0dqq+vH7nxAgQAeH8I/j6gdevWqaenZ+R28ODB0EsCAJwBY/4ihJkzZyqTyejIkSOjPn7kyBE1Nze/o75QKJiepAYATA1j/ggon89r8eLF2rJly8jH0jTVli1b1NbWNtbfDgAwSY3Ly7DXrl2r1atX6w//8A916aWX6oEHHtDAwIA+97nPjce3AwBMQuMygK6//nq99tpruuuuu9TV1aWPfvSjevrpp9/xwgQAwPvXuCUhrFmzRmvWrDnlr5991jTvN41e9MHzvPtmI9smv/Z6t3dtX9+R9y76PxobGr1rq/Lv/gbetytkG/xrC7Z3zseR8Y2rhjfHZTK2NIlM3v+d+bncm6beuZzhDbfGN+nFse0NnZWS/9sTenpsvadN83+DbjadbupdMrw5O5LtzblO/ttZSaxJCLbjGRnuV7JZ2/UTx/5vuK0ktutHkf8+zGT8r4dMxu+aD/4qOADA+xMDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEMS4RfGcrkK+VlV5v8iK4aGMd9/uN/2jWyRpYNg/fqK+9sOm3jOqZnnXJiXbn6yoJCXv2nKl29S7epotcqiu0T8epLbBP3ZEkmqm+0es5KtsETWZrP955SLbz3KRIV5Fkrp+578PX973iqn3R5r8o6zyhbNMvVX0j52pDNeYWpcG/WOB0ootQiiTsR2fOOt/brnEFsWTWpZiiNaRpHzefwTksv73Qc75rYNHQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgJmwWXLlYrVh+OWyHjhpymLL++WuSlNTUe9dGqW13Vkr+8z9JKqbeaeawd21V3W9NvWe1+OfMSdKsWf55etW2ODDlqwy1BdvxyWT8s6+GikVT797+N21rKfgf/2kNfabeZzX512fzb5h6V8r+12a5aMs7rBqq9V9Hsc7UuzzUYKy3ZM35r1uSMrH/SZ6J/fMLJcm5yLs2igy18qvlERAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIIgJG8VTU7dAVVWeERSR/xwtO9s6ktQ/HqS2Zoapdybyj2PpK/7a1Dtb3eVdWzezx9S7ps72c0tqiAcZrtgOUHEg8a6Nh2xxOVU1/r3Lka33wcO/M9W70jTv2rMaLLEwklL/qKS+gQFT60xu2Ls2N73b1Lu64aj/OiJbzE9leLapvv+NRu/aoZ6zTb1VnOdfa7gvPF5f9i7NZvyv40zWr5ZHQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgJmwWXOKmKXF+WXDlsn8OV+JsmV35bMW/NmPr3Tf8G+/aSrzb1HvGDM8cPUnTp9tysrJZ22lTSf1/zikV/bOpJClN/euT1HZ80r5j3rWF6bZ9ksnWmOr/397XvGsbpreYeg/2+9e+MWTNDfTP06tRZOqdiXPetfmCrXfhLNt2FmpK3rW9ef/sPUkafH2md21S9r/uj7M8BrHkNPrV8ggIABDEmA+gr371q4qiaNTtggsuGOtvAwCY5MblV3Af+chH9Nxzz/3+mxh/ZQMAmPrGZTJks1k1NzePR2sAwBQxLs8BvfLKK2ptbdWCBQv02c9+VgcOHDhpbbFYVG9v76gbAGDqG/MBtGTJEm3cuFFPP/20NmzYoP379+sTn/iE+vr6Tljf0dGh+vr6kdvcuXPHekkAgAlozAfQypUr9Wd/9mdauHChli9frn//939Xd3e3fvCDH5ywft26derp6Rm5HTx4cKyXBACYgMb91QENDQ360Ic+pL17957w84VCQYWC7X0oAIDJb9zfB9Tf3699+/appcX25jgAwNQ25gPo85//vDo7O/U///M/+q//+i996lOfUiaT0ac//emx/lYAgElszH8F9+qrr+rTn/60jh07plmzZunjH/+4tm/frlmzZpn6pK6i1PnG4PhvRpRmTOtwzj9K5Gj3T029h9Nd3rWNzYOm3rmC/3bGGVtMSRT77xNJcs4/piSKUlPvbNa/PnaWKBEpSf33S2nI1juXqTbVV9dM9++dt13W3X1vetf2Dr1h6l1M/M+VtGLbJ7H844wykS3+Jmu7m1BVtSFCakaXqXecTvOu7X1tjql3WvbvPR6/LxvzAfToo4+OdUsAwBREFhwAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIIhx/3MMpyqTjZTJemZxOf/NyGZsmVCJfudd2z30M1PvOkMmVE2tf+6VJCkqepeWDXldkuQqtry2jCFrLpuxhXDlcpZT2PbzVuL81+JiWxZcTZVtO+s/6v+HGiuGWDJJ6u/3/yvEuWKtqbflcFblbX+WJRtb9qEt71DG3EDJP6uxUHPiP8550qU0+J/jQ92241Mq+WcMWnaJby2PgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQUzYKJ58PqN83i9qI8pXeffNZW2RNgdf+613bSndb+pdqLHMf1uEUMUSrxPZonXirC3rJZfz385c1hjH4hvXJCkyxrHkIv96l7FFt0TGH/0sqTPD5YqtecH/+FdVpplaZyP/41nI2a7NXMZ/J0ay7ZOcMVpJzr9/Gg2ZWhemveFdO62u39S7MlTyrnXOcG16ZvHwCAgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQxITNgsvEBWUyfhlv2Yx/Tlqp/KZpHcfe/JV3ba7WlsMkTfeuLJcN2W6SXDrsX2v8OSSX2nK1snHOvzZjzKWL/PdLbAlUkxRnDPWRLasvjo2ZaoVq79o0tZ2Hac4/42tatf85K0mxYb/kY/9tlKSsIX/Ppbb8tSix5R3GkX8eZcUVTb3LFf9rOV/oNfWOMoOGdfhfDxXP+wgeAQEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCmMBZcNOViWu8atOKf27T0ddeNq1jYPC33rUzG0ytVS7555iVsrb8KJfzz2vLZP2z2iQpcrbcsyj1z3dziS1nLo3888AiQ3bY8S/wvzxyWb9zdaQ+rjXVZyP/YxRlbD9XTotbvGvjgi0Lzsmwz40ZaUnS7V0bRabWimXMDTT8LB8ZzitJSpz/9ZPP2bLgMob6suoMjf12OI+AAABBmAfQCy+8oKuvvlqtra2KokiPP/74qM8753TXXXeppaVF1dXVWrZsmV555ZWxWi8AYIowD6CBgQEtWrRI69evP+Hn77//fn3rW9/Sgw8+qBdffFHTpk3T8uXLNTzsHykOAJj6zM8BrVy5UitXrjzh55xzeuCBB/TlL39Z11xzjSTpu9/9rpqamvT444/rhhtuOL3VAgCmjDF9Dmj//v3q6urSsmXLRj5WX1+vJUuWaNu2bSf8mmKxqN7e3lE3AMDUN6YDqKurS5LU1NQ06uNNTU0jn3u7jo4O1dfXj9zmzp07lksCAExQwV8Ft27dOvX09IzcDh48GHpJAIAzYEwHUHNzsyTpyJEjoz5+5MiRkc+9XaFQUF1d3agbAGDqG9MBNH/+fDU3N2vLli0jH+vt7dWLL76otra2sfxWAIBJzvwquP7+fu3du3fk3/v379euXbvU2NioefPm6Y477tDf//3f64Mf/KDmz5+vr3zlK2ptbdW11147lusGAExy5gG0Y8cOffKTnxz599q1ayVJq1ev1saNG/WFL3xBAwMDuuWWW9Td3a2Pf/zjevrpp1VVVWX6PuXKsDJlvzgHl/pHeLzx5qumdSTJoHetM0TOSFKl5B87U86WTL0j+WePpHlbRE3qbDElaer/QDtN/eOJJCkylMdZ27qdYR/KVCsp8o+PkqQo8t+HtdVzTL1rchd717q4wdS7nHZ71w6V/p+p90Cpz7vWsPskSXFsi6fKGg5/xXj9ZDP+9xNxzv/+SpKijP99Z1r0v9h8r2PzALriiivk3MnvsKIo0r333qt7773X2hoA8D4S/FVwAID3JwYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCHMUz5lSSYZU8YweSg15bQND3aZ1pKl/DlNStuWYpRX/TKjUFh0mQ/yanG3ZcoktyypJ/BcTVWw/E2UiQ+adMasvttS/SzzVCUW2bL/U+e+XQn6mqXfLjCXetZls03sX/R8DRf98t8Ovv27qPWTYJ7Hxrs6Y7Peu8WTvWEtsu35iQw5klLFlwWUyhvMw8b8vlOf9Jo+AAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBTNgonuNhGH6BGMXykHfXUtG/VpKSyD9iI01scSzlon++Thzb8nLyOUPch7MFjySJ7bQpV/zrjYE2UmxYe8UQJSLbWrIZ23kVJ8awF5f3Lq1UbLlNQ0P93rW102eYehfy/udtFPeZemdi/+1MjNdm1nDdS1KSFr1rU2c7PpEhbkqR7RyX/NeSy/ivI/G8LnkEBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAhiwmbBuTSWS/3mY5qk3n1T/1JJUjn1z4SqlIz5UYacLFcwtZblZwvnbPlRSWLLsqqUbfUWUcZ/OxNj0lxO/scnyZlaK6r4Z7tJUpw1HE/Zcune7P+Vd+1AqcvUu5Tu964dLh8w9c5kh71rnX9U2/H6qGSqLyeD3rWW3DhJyhlyHZ0xTDE13CG61HB/5fz68ggIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABDEhI3iyWSzymR9l+c/R6PIFoFSKflnrJRLtpyfxJCAE8k/jkOS4si/Pq1Ept5JYvu5pVTxzwdJjBEoLuMfD5JxtrycyPlfHkls24eZnG07FfufLOW029Q6SX/pXdtdtK27WD7iXRtnek29M7F/xJOLjTFZzj/mR5Ki2P+ayBmuTUlyqWE7ne3aLCeGc9zQO3F+1wOPgAAAQTCAAABBmAfQCy+8oKuvvlqtra2KokiPP/74qM/feOONiqJo1G3FihVjtV4AwBRhHkADAwNatGiR1q9ff9KaFStW6PDhwyO3Rx555LQWCQCYeswvQli5cqVWrlz5rjWFQkHNzc2nvCgAwNQ3Ls8Bbd26VbNnz9b555+v2267TceOHTtpbbFYVG9v76gbAGDqG/MBtGLFCn33u9/Vli1b9I//+I/q7OzUypUrlSQnfrlsR0eH6uvrR25z584d6yUBACagMX8f0A033DDy/xdffLEWLlyoc889V1u3btXSpUvfUb9u3TqtXbt25N+9vb0MIQB4Hxj3l2EvWLBAM2fO1N69e0/4+UKhoLq6ulE3AMDUN+4D6NVXX9WxY8fU0tIy3t8KADCJmH8F19/fP+rRzP79+7Vr1y41NjaqsbFR99xzj1atWqXm5mbt27dPX/jCF3Teeedp+fLlY7pwAMDkZh5AO3bs0Cc/+cmRf7/1/M3q1au1YcMG7d69W//yL/+i7u5utba26qqrrtLf/d3fqVAomL7PK795Rfm839ccOvQb777V0215YJm4xru2ZMzJqhgy0lxqy5lzMuSvJbbepZIhxE6Siwz73JjZVS77Z8HJmJOVifzrS0VbdlisQdtaMlXetX0D/vlrkuTcG961aWzY35Kc89/OrPwzzyTJpf7nSups53ga2bYzMvwyKTb+4sk3V02SksSWdelS//vl1LAO31rzALriiivk3MkP/DPPPGNtCQB4HyILDgAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQxJj/PaCx8m//9m+KY7/5mM/75zz94aVzTOuII0MW3LDtr7mWy/6ZapWT/EG/k0kMOXOR535+iytas+D86yP/uKnjveX/BZHGL98rY8ywS9Kiqb5Y7vOuTZ0tk9C5jH+tcTvjyJJ3aDs+Fflf99aftF1sy46LU0tOmm0tScX/bro0VG3rXbZlx401HgEBAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIKYsFE8w8NDiiK/+ehS/zk60Fc2raO61hLFY4u1KA3711bKtmiQJDFE1JRtP4ekGVteTlzxX3vZGPUiz3NEksqG6BZJUuofIZTL2PZhuWw7DyvpoHdtFFujkvyPZ8UYl5ON/WN+0tS/VpIs1S6yrds527niDGtPDdeDJA0P+x+f4X5bFI9L/e/fJMu16VfLIyAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEBM2Cy6OY+8suFLJP+fpjWN9pnW0VOe8a8slWxZc2ZAFl1izw8r++VGWLD1JymRt9ZWsf/ZVZMyCs6zFGWPm0tR/H5ZLtt7O2bLJ4qz/N8j4n7KSpMiQ7eci23mYJJYsONvC09h/3dmMNQvOVK7I8AVpYmteKfmf40nZlgWXVvzvsyoV/2NfKfvlEfIICAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQxISN4pGi/729N+f84z7efMMWxTNzdp13bSWxzfP+Af+Imup+/9gRScpW+dfm87ZokFxqi2ORIV4nmzGekqn/sXcV//0tSc6wlMTZjk9kW4qSin+UTOpsuUCZrGEfZoz70JJpkxp3imdUlyRF1mgdYyRUIv+1V4zRV8MV//qhoi0OrFL2P/aJ87/uE8/7CB4BAQCCMA2gjo4OXXLJJaqtrdXs2bN17bXXas+ePaNqhoeH1d7erhkzZmj69OlatWqVjhw5MqaLBgBMfqYB1NnZqfb2dm3fvl3PPvusyuWyrrrqKg0MDIzU3HnnnXryySf12GOPqbOzU4cOHdJ111035gsHAExupl+4P/3006P+vXHjRs2ePVs7d+7U5Zdfrp6eHj300EPatGmTrrzySknSww8/rA9/+MPavn27Pvaxj43dygEAk9ppPQfU09MjSWpsbJQk7dy5U+VyWcuWLRupueCCCzRv3jxt27bthD2KxaJ6e3tH3QAAU98pD6A0TXXHHXfosssu00UXXSRJ6urqUj6fV0NDw6japqYmdXV1nbBPR0eH6uvrR25z58491SUBACaRUx5A7e3tevnll/Xoo4+e1gLWrVunnp6ekdvBgwdPqx8AYHI4pfcBrVmzRk899ZReeOEFzZkzZ+Tjzc3NKpVK6u7uHvUo6MiRI2pubj5hr0KhoEKhcCrLAABMYqZHQM45rVmzRps3b9bzzz+v+fPnj/r84sWLlcvltGXLlpGP7dmzRwcOHFBbW9vYrBgAMCWYHgG1t7dr06ZNeuKJJ1RbWzvyvE59fb2qq6tVX1+vm266SWvXrlVjY6Pq6up0++23q62tjVfAAQBGMQ2gDRs2SJKuuOKKUR9/+OGHdeONN0qSvvGNbyiOY61atUrFYlHLly/Xd77znTFZLABg6jANIJ9cp6qqKq1fv17r168/5UUd/2b+WXCR4TeJ/f2DpmUMDvo/P1U9zRDAJmlwyD+X7o03Kqbehng81Uy39a6uMr52xZAHls0Yc+ky/mvJ5G1PebrYkO+V2Nadylafyfgf0Ciy5dK5smEtFVvvjOH4mF8RZTivUkOe2v9+ham6rCH/2ortPOwf8M+jHBqy3QeZttL55xH61pIFBwAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAIggEEAAiCAQQACIIBBAAI4pT+HMMZEaW+STymKJ7icNm0jO43/CM26uprTL3LxZx37fCQIQZD0kCvf8hGmtpiYZwxdiYylGdztgiUOC4Zqo1RPM7w85lxH8ax7We/bNZ/7c62CxUZ1mKplaQoMkQIGX8etmxmart85Jz/tSlJFQ141w4PTTP1HnzzbO/atNxg6l2pDBtq/XdiuUQUDwBgAmMAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCmLhZcIakJydLDpdt5na/6Z+V1Dpnuql3PudfXynZssYG+v0z0pwpVcv+U0s+4xnqJ6lcZeudyfjvl3zOtg+T2BiqZpBmbL0jQ6BeFNmCz2LD8Ymdf60klZ3/ulPjeZiJ/M9El9p6J4lxOxP/7LjBvnpT71L/LO/aSrFg610Z9O9d8T+WpXLFq45HQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAICZuFE+USp5pGJFvoaQotm3yQJ9/pM1rR3tMvZvPrvGuLZdtUSKlIf/aTOy/jZJUlTeVq1L2Pz5pxRaBEinjXeuMMTJJYovusTAk60iSXOoXbSJJScUYIRT7R/dYoo+O1/vXZg3ROpKUMezENLHFE6Vp2VQ/PDDTu7b/jbNNvctF//1SSWzrLhsu/UrF/xwsl4jiAQBMYAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQDCAAQBAMIABAEAwgAEAQEzcLzvnnWTlLFlxkzQPzD7M6eqTX1HvGLP8suOqqWlPvkiG3qVT0r5WkYtGWB1Yq+9dbaiWpYMhrK5Vt25lJDeegNX4tNuaeGULVksi4GMP1Y1531pDXljHmADr/tSQV4zk7bNvOYl+Dd21abDL1TlNDlmJaNPb2387UGY6lZy2PgAAAQZgGUEdHhy655BLV1tZq9uzZuvbaa7Vnz55RNVdccYWiKBp1u/XWW8d00QCAyc80gDo7O9Xe3q7t27fr2WefVblc1lVXXaWBgYFRdTfffLMOHz48crv//vvHdNEAgMnP9BzQ008/PerfGzdu1OzZs7Vz505dfvnlIx+vqalRc3Pz2KwQADAlndZzQD09x/8AW2Nj46iPf+9739PMmTN10UUXad26dRocHDxpj2KxqN7e3lE3AMDUd8qvgkvTVHfccYcuu+wyXXTRRSMf/8xnPqNzzjlHra2t2r17t774xS9qz549+uEPf3jCPh0dHbrnnntOdRkAgEnqlAdQe3u7Xn75Zf3kJz8Z9fFbbrll5P8vvvhitbS0aOnSpdq3b5/OPffcd/RZt26d1q5dO/Lv3t5ezZ0791SXBQCYJE5pAK1Zs0ZPPfWUXnjhBc2ZM+dda5csWSJJ2rt37wkHUKFQUKFQOJVlAAAmMdMAcs7p9ttv1+bNm7V161bNnz//Pb9m165dkqSWlpZTWiAAYGoyDaD29nZt2rRJTzzxhGpra9XV1SVJqq+vV3V1tfbt26dNmzbpT/7kTzRjxgzt3r1bd955py6//HItXLhwXDYAADA5mQbQhg0bJB1/s+n/9fDDD+vGG29UPp/Xc889pwceeEADAwOaO3euVq1apS9/+ctjtmAAwNRg/hXcu5k7d646OztPa0Ej30tOkmf2kCHmyRCrdJwhg6u/35Y39drRk788/e0WfHCmqbcqQ96lpVJiaj00WDbVZ3OGDLbYGqrmX18xZLtJUi7v/y6FKGM79pFxOzOGN0wY49osl4+yloVIyiQl79qK/6UmSUor/s8dFweqTb3LQ7anDHLyr0+SvKl3Usl516YV23kVRf7XZsZw7H1ryYIDAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAARxyn8PaLxF//ufD2cKE7Fm8fhLU//IDEnq+l2/d21tnS1KZGZTrXetNbolTf3jVSRpeMA/HsTaO0kMUTwl27GvqvHPhomztt5RZI3u8Y9LimNrb//6XNbWO87438W4So2pd6XY4F2blmaYeldl3zvpfxTX+N41b5Wmtj8/k80YongS/wguSYrkf/0kif85mCR+cV08AgIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEwQACAATBAAIABMEAAgAEMWGz4NI0VeQZr5XJ+Gd2WTnnn30VKW/qPThQ9K595ddHTL3TdKZ37ewW/9w4Scrk/POjjq/FfzsrRf98PEkakCH7Kq2YeieJ/+WRyRl/lots+9CSHRfHtt6WLEDrtRY5/wxDV/HPU5OkuHK2d20hO9fUO6k0mOorFf+dmDXk40mSc/7H0xmy3SQpMhz7XM7/2KepXy2PgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQTCAAABBMIAAAEEwgAAAQUzYKJ66unrFnhkhvb2947gSzzwgSYa0lONczru0vzcxtd6753Xv2uHhelPvs+ecZaqvqanyL45tcUaRG/auLfsnAkmShpz/5RFnbQffyVYfGzJTIt8Mq7fW4vzrc9k6U++awixDbaupdy7f5F3rkumm3i41xuWkZe/aoZIhPkpSkvhHSDlnu5+ILMlKhocrTn7r4BEQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIAgGEAAgCAYQACAIBhAAIIgJmwV3zZ/+qfKFglftSy+95N33N7/5jWkdfX193rUuseUwZWP/IKZMXG3qPdjvn5G2d89rpt7Hjg6Y6hsb/XO46s+qMfWeNs0/xy6bNebMGX48q6SDpt7lsn++lySlif+5Ekd+181bZs70z1RraJpr6t1Q458FF0e2Y18p+2fYxbHtri4xXsvlsv/1VjKGEqZJaqi2hLtJWcNJXlXln13pm0nHIyAAQBCmAbRhwwYtXLhQdXV1qqurU1tbm370ox+NfH54eFjt7e2aMWOGpk+frlWrVunIkSNjvmgAwORnGkBz5szRfffdp507d2rHjh268sordc011+gXv/iFJOnOO+/Uk08+qccee0ydnZ06dOiQrrvuunFZOABgcjP9YvTqq68e9e9/+Id/0IYNG7R9+3bNmTNHDz30kDZt2qQrr7xSkvTwww/rwx/+sLZv366PfexjY7dqAMCkd8rPASVJokcffVQDAwNqa2vTzp07VS6XtWzZspGaCy64QPPmzdO2bdtO2qdYLKq3t3fUDQAw9ZkH0M9//nNNnz5dhUJBt956qzZv3qwLL7xQXV1dyufzamhoGFXf1NSkrq6uk/br6OhQfX39yG3uXNurbAAAk5N5AJ1//vnatWuXXnzxRd12221avXq1fvnLX57yAtatW6eenp6R28GDB0+5FwBg8jC/Dyifz+u8886TJC1evFg//elP9c1vflPXX3+9SqWSuru7Rz0KOnLkiJqbm0/ar1AoqOD5fh8AwNRx2u8DStNUxWJRixcvVi6X05YtW0Y+t2fPHh04cEBtbW2n+20AAFOM6RHQunXrtHLlSs2bN099fX3atGmTtm7dqmeeeUb19fW66aabtHbtWjU2Nqqurk6333672traeAUcAOAdTAPo6NGj+vM//3MdPnxY9fX1WrhwoZ555hn98R//sSTpG9/4huI41qpVq1QsFrV8+XJ95zvfOaWFfeADH1BVtV/8TEtLi3ffhQsXmtZhie753e9eNfV+8403vWsHB21RL3Hif2jTiiXqQ3r9qH/siCQde80/eiSb7Tb1zub8o0eyGf8okeO9/fdh1tZa1VW22JnGxkbv2vnzzzX1PmfOB7xrCwXjhjr/41Mq287DyHD3laZlU+80tUXxZGL/WKBs1vbMR1n+sU0VY4RQjeE8dIbD41K/427aEw899NC7fr6qqkrr16/X+vXrLW0BAO9DZMEBAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCMKdhjzfnnCRpeNg/7sVSWyr5x8JIUqXiH+GRGGMw0tQ/28JZcjD0+/041rWnUj+evdPUvz6NrL3997mhVJKUJLYvqFT8z61yyRY7Uyz6XxPW8zCO/aN4EmMklAwRNdL4HXtJqlT811JOLOuWyobe1vOqWMx71/qHDf3+nHqv6zly43lvcgpeffVV/igdAEwBBw8e1Jw5c076+Qk3gNI01aFDh1RbW6so+v3M7e3t1dy5c3Xw4EHV1dUFXOH4YjunjvfDNkps51QzFtvpnFNfX59aW1sVxyd/pmfC/QoujuN3nZh1dXVT+uC/he2cOt4P2yixnVPN6W5nfX39e9bwIgQAQBAMIABAEJNmABUKBd19990qFAqhlzKu2M6p4/2wjRLbOdWcye2ccC9CAAC8P0yaR0AAgKmFAQQACIIBBAAIggEEAAhi0gyg9evX6wMf+ICqqqq0ZMkS/fd//3foJY2pr371q4qiaNTtggsuCL2s0/LCCy/o6quvVmtrq6Io0uOPPz7q88453XXXXWppaVF1dbWWLVumV155JcxiT8N7beeNN974jmO7YsWKMIs9RR0dHbrkkktUW1ur2bNn69prr9WePXtG1QwPD6u9vV0zZszQ9OnTtWrVKh05ciTQik+Nz3ZeccUV7ziet956a6AVn5oNGzZo4cKFI282bWtr049+9KORz5+pYzkpBtD3v/99rV27Vnfffbd+9rOfadGiRVq+fLmOHj0aemlj6iMf+YgOHz48cvvJT34SekmnZWBgQIsWLdL69etP+Pn7779f3/rWt/Tggw/qxRdf1LRp07R8+XJTuOxE8F7bKUkrVqwYdWwfeeSRM7jC09fZ2an29nZt375dzz77rMrlsq666ioNDAyM1Nx555168skn9dhjj6mzs1OHDh3SddddF3DVdj7bKUk333zzqON5//33B1rxqZkzZ47uu+8+7dy5Uzt27NCVV16pa665Rr/4xS8kncFj6SaBSy+91LW3t4/8O0kS19ra6jo6OgKuamzdfffdbtGiRaGXMW4kuc2bN4/8O01T19zc7L72ta+NfKy7u9sVCgX3yCOPBFjh2Hj7djrn3OrVq90111wTZD3j5ejRo06S6+zsdM4dP3a5XM499thjIzW/+tWvnCS3bdu2UMs8bW/fTuec+6M/+iP3V3/1V+EWNU7OOuss90//9E9n9FhO+EdApVJJO3fu1LJly0Y+Fsexli1bpm3btgVc2dh75ZVX1NraqgULFuizn/2sDhw4EHpJ42b//v3q6uoadVzr6+u1ZMmSKXdcJWnr1q2aPXu2zj//fN122206duxY6CWdlp6eHklSY2OjJGnnzp0ql8ujjucFF1ygefPmTerj+fbtfMv3vvc9zZw5UxdddJHWrVunwcHBEMsbE0mS6NFHH9XAwIDa2trO6LGccGGkb/f6668rSRI1NTWN+nhTU5N+/etfB1rV2FuyZIk2btyo888/X4cPH9Y999yjT3ziE3r55ZdVW1sbenljrqurS5JOeFzf+txUsWLFCl133XWaP3++9u3bp7/927/VypUrtW3bNmUy/n8vZ6JI01R33HGHLrvsMl100UWSjh/PfD6vhoaGUbWT+XieaDsl6TOf+YzOOecctba2avfu3friF7+oPXv26Ic//GHA1dr9/Oc/V1tbm4aHhzV9+nRt3rxZF154oXbt2nXGjuWEH0DvFytXrhz5/4ULF2rJkiU655xz9IMf/EA33XRTwJXhdN1www0j/3/xxRdr4cKFOvfcc7V161YtXbo04MpOTXt7u15++eVJ/xzleznZdt5yyy0j/3/xxRerpaVFS5cu1b59+3Tuueee6WWesvPPP1+7du1ST0+P/vVf/1WrV69WZ2fnGV3DhP8V3MyZM5XJZN7xCowjR46oubk50KrGX0NDgz70oQ9p7969oZcyLt46du+34ypJCxYs0MyZMyflsV2zZo2eeuop/fjHPx71Z1Oam5tVKpXU3d09qn6yHs+TbeeJLFmyRJIm3fHM5/M677zztHjxYnV0dGjRokX65je/eUaP5YQfQPl8XosXL9aWLVtGPpamqbZs2aK2traAKxtf/f392rdvn1paWkIvZVzMnz9fzc3No45rb2+vXnzxxSl9XKXjf/X32LFjk+rYOue0Zs0abd68Wc8//7zmz58/6vOLFy9WLpcbdTz37NmjAwcOTKrj+V7beSK7du2SpEl1PE8kTVMVi8UzeyzH9CUN4+TRRx91hULBbdy40f3yl790t9xyi2toaHBdXV2hlzZm/vqv/9pt3brV7d+/3/3nf/6nW7ZsmZs5c6Y7evRo6KWdsr6+PvfSSy+5l156yUlyX//6191LL73kfvvb3zrnnLvvvvtcQ0ODe+KJJ9zu3bvdNddc4+bPn++GhoYCr9zm3bazr6/Pff7zn3fbtm1z+/fvd88995z7gz/4A/fBD37QDQ8Ph166t9tuu83V19e7rVu3usOHD4/cBgcHR2puvfVWN2/ePPf888+7HTt2uLa2NtfW1hZw1XbvtZ179+519957r9uxY4fbv3+/e+KJJ9yCBQvc5ZdfHnjlNl/60pdcZ2en279/v9u9e7f70pe+5KIocv/xH//hnDtzx3JSDCDnnPv2t7/t5s2b5/L5vLv00kvd9u3bQy9pTF1//fWupaXF5fN5d/bZZ7vrr7/e7d27N/SyTsuPf/xjJ+kdt9WrVzvnjr8U+ytf+YprampyhULBLV261O3Zsyfsok/Bu23n4OCgu+qqq9ysWbNcLpdz55xzjrv55psn3Q9PJ9o+Se7hhx8eqRkaGnJ/+Zd/6c466yxXU1PjPvWpT7nDhw+HW/QpeK/tPHDggLv88stdY2OjKxQK7rzzznN/8zd/43p6esIu3Ogv/uIv3DnnnOPy+bybNWuWW7p06cjwce7MHUv+HAMAIIgJ/xwQAGBqYgABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgmAAAQCCYAABAIJgAAEAgvj/umwREv9G4CAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "example_dataset = cifar100_train.create_tf_dataset_for_client(cifar100_train.client_ids[0])\n",
        "\n",
        "example_element = next(iter(example_dataset))\n",
        "plt.imshow(example_element['image'].numpy(), cmap='gray', aspect='equal')\n",
        "plt.grid(False)\n",
        "_ = plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6wB6PggHO3g"
      },
      "source": [
        "Now let's visualize the number of examples on each client for each MNIST digit label. In the federated environment, the number of examples on each client can vary quite a bit, depending on user behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0pwnQZUKea2"
      },
      "source": [
        "### Preprocessing the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMd01egqy9we"
      },
      "source": [
        "Since the data is already a `tf.data.Dataset`,  preprocessing can be accomplished using Dataset transformations. Here, we flatten the `28x28` images\n",
        "into `784`-element arrays, shuffle the individual examples, organize them into batches, and rename the features\n",
        "from `pixels` and `label` to `x` and `y` for use with Keras. We also throw in a\n",
        "`repeat` over the data set to run several epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 50\n",
        "SHUFFLE_BUFFER = 250\n",
        "PREFETCH_BUFFER = 25 # half of batch size\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(element):\n",
        "        \"\"\"Adjust the function for CIFAR100's 32x32x3 images.\"\"\"\n",
        "        # Reshape and normalize CIFAR100 images\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(element['image'], [-1, 32, 32, 3]),  # Normalize images to [0,1]\n",
        "            y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
        "        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "# Here's a simple helper function that will construct a list of datasets from the given set of users as an input to a round of training or evaluation.\n",
        "def make_federated_data(client_data, client_ids):\\\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9PfjOtAVqw"
      },
      "source": [
        "Sample the set of clients once, andreuse the same set across rounds to speed up convergence (intentionally over-fitting to these few user's data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GZ6NYHxB8xer"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of client datasets: 10\n",
            "First dataset: <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 32, 32, 3), dtype=tf.uint8, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))])>\n"
          ]
        }
      ],
      "source": [
        "sample_clients = cifar100_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(cifar100_train, sample_clients)\n",
        "\n",
        "print(f'Number of client datasets: {len(federated_train_data)}')\n",
        "print(f'First dataset: {federated_train_data[0]}')\n",
        "\n",
        "preprocessed_example_dataset = preprocess(example_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Creating a model with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        # tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        # tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        # tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        # tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        # tf.keras.layers.Flatten(),\n",
        "        # tf.keras.layers.Dense(256, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.5),\n",
        "        # tf.keras.layers.Dense(128, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.5),\n",
        "        # tf.keras.layers.Dense(100, activation='softmax')\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.GroupNormalization(groups=8, axis=3),  # Group Normalization\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.GroupNormalization(groups=8, axis=3),  # Group Normalization\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(100, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "**Note:** we do not compile the model yet. The loss, metrics, and optimizers are introduced later.\n",
        "\n",
        "In order to use any model with TFF, it needs to be wrapped in an instance of the\n",
        "`tff.learning.models.VariableModel` interface, which exposes methods to stamp the model's\n",
        "forward pass, metadata properties, etc., similarly to Keras, but also introduces\n",
        "additional elements, such as ways to control the process of computing federated\n",
        "metrics. Let's not worry about this for now; if you have a Keras model like the\n",
        "one we've just defined above, you can have TFF wrap it for you by invoking\n",
        "`tff.learning.models.from_keras_model`, passing the model and a sample data batch as\n",
        "arguments, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Training the model on federated data\n",
        "\n",
        "Now that we have a model wrapped as `tff.learning.models.VariableModel` for use with TFF, we\n",
        "can let TFF construct a Federated Averaging algorithm by invoking the helper\n",
        "function `tff.learning.algorithms.build_weighted_fed_avg`, as follows.\n",
        "\n",
        "Keep in mind that the argument needs to be a constructor (such as `model_fn`\n",
        "above), not an already-constructed instance, so that the construction of your\n",
        "model can happen in a context controlled by TFF (if you're curious about the\n",
        "reasons for this, we encourage you to read the follow-up tutorial on\n",
        "[custom algorithms](custom_federated_algorithms_1.ipynb)).\n",
        "\n",
        "One critical note on the Federated Averaging algorithm below, there are **2**\n",
        "optimizers: a _client_optimizer_ and a _server_optimizer_. The\n",
        "_client_optimizer_ is only used to compute local model updates on each client.\n",
        "The _server_optimizer_ applies the averaged update to the global model at the\n",
        "server. In particular, this means that the choice of optimizer and learning rate\n",
        "used may need to be different than the ones you have used to train the model on\n",
        "a standard i.i.d. dataset. We recommend starting with regular SGD, possibly with\n",
        "a smaller learning rate than usual. The learning rate we use has not been\n",
        "carefully tuned, feel free to experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.05),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "Let's invoke the `initialize` computation to construct the server state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6cagCWlZmcch"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-22 11:49:44.284674: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.284807: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.310521: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.310618: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
          ]
        }
      ],
      "source": [
        "train_state = training_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "The second of the pair of federated computations, `next`, represents a single\n",
        "round of Federated Averaging, which consists of pushing the server state\n",
        "(including the model parameters) to the clients, on-device training on their\n",
        "local data, collecting and averaging model updates, and producing a new updated\n",
        "model at the server.\n",
        "\n",
        "Conceptually, you can think of `next` as having a functional type signature that\n",
        "looks as follows.\n",
        "\n",
        "```\n",
        "SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
        "```\n",
        "\n",
        "In particular, one should think about `next()` not as being a function that runs on a server, but rather being a declarative functional representation of the entire decentralized computation - some of the inputs are provided by the server (`SERVER_STATE`), but each participating device contributes its own local dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Let's run a few more rounds. As noted earlier, typically at this point you would\n",
        "pick a subset of your simulation data from a new randomly selected sample of\n",
        "users for each round in order to simulate a realistic deployment in which users\n",
        "continuously come and go, but in this interactive notebook, for the sake of\n",
        "demonstration we'll just reuse the same users, so that the system converges\n",
        "quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qrJkQuCRJP9C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-22 11:49:44.612085: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.612247: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.766551: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.766663: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.771335: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.771433: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.777924: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.778024: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.785580: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.785676: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.798500: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.798592: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.806837: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.806929: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.815705: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.815790: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.826278: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.826365: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.834735: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.834826: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.837525: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.837608: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.841994: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.842073: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.846827: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.846915: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
            "2024-07-22 11:49:44.864512: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:49:44.864619: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.068), ('loss', 5.380441), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1034), ('loss', 4.5626945), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1004), ('loss', 4.525102), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0914), ('loss', 4.4900827), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0886), ('loss', 4.5083075), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0872), ('loss', 4.4765897), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.068), ('loss', 4.462251), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0842), ('loss', 4.4175477), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0722), ('loss', 4.3983955), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0874), ('loss', 4.297259), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 11, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0912), ('loss', 4.1582694), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 12, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.104), ('loss', 4.0561123), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 13, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1132), ('loss', 4.042881), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 14, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1204), ('loss', 3.9090593), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 15, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1338), ('loss', 3.7517493), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 16, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1494), ('loss', 3.6211097), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 17, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1738), ('loss', 3.5053937), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 18, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1848), ('loss', 3.460466), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round 19, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2072), ('loss', 3.3433695), ('num_examples', 5000), ('num_batches', 100)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "NUM_ROUNDS = 20\n",
        "for round_num in range(1, NUM_ROUNDS):\n",
        "  result = training_process.next(train_state, federated_train_data)\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joHYzn9jcs0Y"
      },
      "source": [
        "Training loss is decreasing after each round of federated training, indicating\n",
        "the model is converging. There are some important caveats with these training\n",
        "metrics, however, see the section on *Evaluation* later in this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iswqa2Uj7phq"
      },
      "source": [
        "To see these metrics within TensorBoard, refer to the steps listed above in \"Displaying model metrics in TensorBoard\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7lz59lMJ0kj"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "All of our experiments so far presented only federated training metrics - the\n",
        "average metrics over all batches of data trained across all clients in the\n",
        "round. This introduces the normal concerns about overfitting, especially since\n",
        "we used the same set of clients on each round for simplicity, but there is an\n",
        "additional notion of overfitting in training metrics specific to the Federated\n",
        "Averaging algorithm. This is easiest to see if we imagine each client had a\n",
        "single batch of data, and we train on that batch for many iterations (epochs).\n",
        "In this case, the local model will quickly exactly fit to that one batch, and so\n",
        "the local accuracy metric we average will approach 1.0. Thus, these training\n",
        "metrics can be taken as a sign that training is progressing, but not much more.\n",
        "\n",
        "To perform evaluation on federated data, you can construct another *federated\n",
        "computation* designed for just this purpose, using the\n",
        "`tff.learning.build_federated_evaluation` function, and passing in your model\n",
        "constructor as an argument. Note that unlike with Federated Averaging, where\n",
        "we've used `MnistTrainableModel`, it suffices to pass the `MnistModel`.\n",
        "Evaluation doesn't perform gradient descent, and there's no need to construct\n",
        "optimizers.\n",
        "\n",
        "For experimentation and research, when a centralized test dataset is available,\n",
        "[Federated Learning for Text Generation](federated_learning_for_text_generation.ipynb)\n",
        "demonstrates another evaluation option: taking the trained weights from\n",
        "federated learning, applying them to a standard Keras model, and then simply\n",
        "calling `tf.keras.models.Model.evaluate()` on a centralized dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Federated Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nRiXyqnXM2VO"
      },
      "outputs": [],
      "source": [
        "# evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)\n",
        "# evaluation_state = evaluation_process.initialize()\n",
        "# model_weights = training_process.get_model_weights(train_state)\n",
        "# evaluation_state = evaluation_process.set_model_weights(evaluation_state, model_weights)\n",
        "# evaluation_output = evaluation_process.next(evaluation_state, federated_train_data)\n",
        "\n",
        "# federated_test_data = make_federated_data(cifar100_test, cifar100_test.client_ids[0:NUM_CLIENTS])\n",
        "\n",
        "# for round_num in range(1, NUM_ROUNDS + 1):\n",
        "#     evaluation_output = evaluation_process.next(evaluation_state, federated_test_data)\n",
        "    \n",
        "#     # Extract metrics from the evaluation output\n",
        "#     metrics = evaluation_output.metrics\n",
        "#     print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Central Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataset(element):\n",
        "    # Adjust the dataset to match the model's input requirements\n",
        "    # Assuming 'image' key contains the input images and 'label' key contains the labels\n",
        "    return collections.OrderedDict(\n",
        "        conv2d_9_input=tf.reshape(element['image'], [-1, 32, 32, 3]),  # Reshape and assign to the expected input key\n",
        "        y=tf.reshape(element['label'], [-1, 1])  # Reshape labels if necessary\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-22 11:50:34.070958: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
            "2024-07-22 11:50:34.071045: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tEval: metrics=[4.601626396179199, 0.04100000113248825]\n"
          ]
        }
      ],
      "source": [
        "keras_model = create_keras_model()\n",
        "keras_model.compile(\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "model_weights = training_process.get_model_weights(train_state)\n",
        "model_weights.assign_weights_to(keras_model)\n",
        "adjusted_dataset = cifar100_test.create_tf_dataset_from_all_clients().map(prepare_dataset)\n",
        "adjusted_dataset = adjusted_dataset.map(lambda x: (x['conv2d_9_input'], x['y']))\n",
        "\n",
        "metrics = keras_model.evaluate(adjusted_dataset, steps=10000, verbose=0)\n",
        "print('\\tEval: metrics={}'.format(metrics))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "federated_learning_for_image_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
